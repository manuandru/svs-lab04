{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carla 03\n",
    "\n",
    "## Conda Setup\n",
    "\n",
    "Please run the following from `Anaconda Powershell Prompt` (or any other terminal with `conda` installed).\n",
    "\n",
    "From Lab PC, you can find it in the start menu or in the Desktop.\n",
    "\n",
    "### 1. Environment creation\n",
    "\n",
    "Create a new environment with the following command (you can skip this step if you already have a conda environment):\n",
    "\n",
    "```bash\n",
    "conda create -n carla-env python=3.7\n",
    "```\n",
    "\n",
    "### 2. Environment activation\n",
    "\n",
    "Activate the environment with the following command:\n",
    "\n",
    "```bash\n",
    "conda activate carla-env\n",
    "```\n",
    "\n",
    "### 3. Package installation\n",
    "\n",
    "Install the required packages with the following command (run it where the `requirements.txt` file is located):\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 4. VSCode setup\n",
    "\n",
    "If you are using VSCode, you can select the conda environment by clicking on the bottom left corner:\n",
    "\n",
    "`Select kernel > Python Environments > carla-env`\n",
    "\n",
    "Let vscode install the required packages for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla, time, pygame, math, random, cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpful functions used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spectator_to(transform, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "    \n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "    \n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "    \n",
    "    spectator.set_transform(spectator_transform)\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def draw_on_screen(world, transform, content='O', color=carla.Color(0, 255, 0), life_time=20):\n",
    "    world.debug.draw_string(transform.location, content, color=color, life_time=life_time)\n",
    "\n",
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=1.2, z=1.2), carla.Rotation(pitch=-10))):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDE suggestions\n",
    "\n",
    "In VSCode, you can get suggestions for functions and classes by pressing `Ctrl + Space`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = world.get_map()\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, carla does not provide docs for the functions and classes, so we need to install it manually.\n",
    "\n",
    "It can be done in VSCode with the following the instructions (resumed below):\n",
    "\n",
    "1. Go to the repo https://github.com/aasewold/carla-python-stubs\n",
    "2. Go to the releases section\n",
    "3. Download `*.pyi` file (i.e `__init__.pyi` and `command.pyi`)  that match carla version (e.g 0.9.15)\n",
    "4. Put the file in `./typings/carla` ([vscode reference](https://code.visualstudio.com/docs/python/settings-reference))\n",
    "\n",
    "> **Note**: `./typings/carla` should be relative to the root of the vscode project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensors\n",
    "\n",
    "Sensors are another type of actors, usually spawned attached to a vehicle, designed to retrieve data from the world. The type of data depends on the sensor, but it can range from RGB images, LiDAR scans or even collision information.\n",
    "\n",
    "Sensors are divided into two main categories:\n",
    "\n",
    "- **Regular sensors**: these sensors retrieve data at a fixed rate, usually every tick (e.g RGB cameras).\n",
    "- **Trigger sensors**: these sensors only retrieve data when a certain condition is met (e.g collision sensors).\n",
    "\n",
    "Sensors details can be found in the [CARLA documentation](https://carla.readthedocs.io/en/latest/ref_sensors/).\n",
    "\n",
    "![Sensors](img/sensors.jpg)\n",
    "\n",
    "### Exploring sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = world.get_blueprint_library().filter('sensor.*')\n",
    "\n",
    "for sensor in sensors:\n",
    "    print(sensor.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "\n",
    "camera_bp.set_attribute('image_size_x', '1280')\n",
    "camera_bp.set_attribute('image_size_y', '720')\n",
    "camera_bp.set_attribute('fov', '120')\n",
    "camera_bp.set_attribute('sensor_tick', '0')\n",
    "\n",
    "spawn_point = carla.Transform()\n",
    "camera = world.spawn_actor(camera_bp, spawn_point)\n",
    "\n",
    "time.sleep(1)\n",
    "move_spectator_to(camera.get_transform())\n",
    "\n",
    "# count = 0\n",
    "# def handle_image(image):\n",
    "#     global count\n",
    "#     image.save_to_disk(f'output/{count}.png')\n",
    "#     count += 1\n",
    "\n",
    "# camera.listen(lambda image: handle_image(image))\n",
    "\n",
    "time.sleep(10)\n",
    "camera.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's spawn a vehicle and a camera in a particular position and see what the camera sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_position = carla.Transform(carla.Location(x=-34, y=31, z=11), carla.Rotation(pitch=-18, yaw=-170, roll=0))\n",
    "\n",
    "camera = spawn_camera(transform=camera_position)\n",
    "vehicle = spawn_vehicle()\n",
    "\n",
    "camera.listen(lambda image: image.save_to_disk('output/camera.png'))\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "camera.destroy()\n",
    "vehicle.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach a camera to a vehicle\n",
    "\n",
    "In order to acquire images from the point of view of a vehicle, we can attach a camera to it and retrieve what it sees, based on the camera's position and orientation. When the camera is attached to a vehicle, it will move with the vehicle itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = spawn_vehicle()\n",
    "camera = spawn_camera(attach_to=vehicle)\n",
    "\n",
    "camera.listen(lambda image: image.save_to_disk(f'output/{image.frame}.png'))\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "camera.destroy()\n",
    "vehicle.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many images have been captured by the camera so far?\n",
    "\n",
    "### Live camera feed\n",
    "\n",
    "We can also visualize the camera feed in real-time. This is useful for debugging and understanding what the camera sees.\n",
    "\n",
    "We can use the `opencv` library to create a window and display the camera feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = spawn_vehicle()\n",
    "camera = spawn_camera(attach_to=vehicle)\n",
    "\n",
    "video_output = np.zeros((600, 800, 4), dtype=np.uint8)\n",
    "def camera_callback(image):\n",
    "    global video_output\n",
    "    video_output = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "camera.listen(lambda image: camera_callback(image))\n",
    "\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "cv2.namedWindow('RGB Camera', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "running = True\n",
    "\n",
    "try:\n",
    "    while running:\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            running = False\n",
    "            break\n",
    "        cv2.imshow('RGB Camera', video_output)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    camera.destroy()\n",
    "    vehicle.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic light control\n",
    "\n",
    "In this example, we will create a simple script that turns on the vehicle's lights when it gets dark and turns them off when it gets bright. It's been introduced a time threshold to avoid flickering when the light level is close to the brightness threshold.\n",
    "\n",
    "To change the weather conditions, we can use the `PythonAPI\\util\\config.py` script.\n",
    "\n",
    "```bash\n",
    "python ./config.py --weather ClearNoon\n",
    "python ./config.py --weather ClearNight\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = spawn_vehicle(pattern='vehicle.mercedes.coupe_2020')\n",
    "camera = spawn_camera(attach_to=vehicle)\n",
    "\n",
    "video_output = np.zeros((600, 800, 4), dtype=np.uint8)\n",
    "def camera_callback(image):\n",
    "    global video_output\n",
    "    video_output = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "camera.listen(lambda image: camera_callback(image))\n",
    "\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "cv2.namedWindow('Automatic light control', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "running = True\n",
    "\n",
    "# ============ Day/Night Classification ============ #\n",
    "\n",
    "is_night = False\n",
    "start_time = time.time()\n",
    "brightness_threshold = 50\n",
    "time_threshold = 5\n",
    "\n",
    "def is_night_image_classificator(image):\n",
    "    global is_night, start_time, brightness_threshold, time_threshold\n",
    "    \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n",
    "    light_intensity = np.mean(gray_image)\n",
    "\n",
    "    current_time = time.time()\n",
    "    if (light_intensity > brightness_threshold and not is_night) or (light_intensity < brightness_threshold and is_night):\n",
    "        start_time = time.time()\n",
    "\n",
    "    elapsed_time = current_time - start_time\n",
    "    print(f'Light intensity: {light_intensity}, Elapsed time: {elapsed_time:.2f}s', end='\\r')\n",
    "    \n",
    "    if elapsed_time >= time_threshold:\n",
    "        is_night = not is_night\n",
    "\n",
    "    return is_night\n",
    "\n",
    "# ============ Day/Night Classification ============ #\n",
    "\n",
    "try:\n",
    "    while running:\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            running = False\n",
    "            break\n",
    "        cv2.imshow('Automatic light control', video_output)\n",
    "        \n",
    "        move_spectator_to(vehicle.get_transform(), distance=-10.0, z=2.0, pitch=0, yaw=180)\n",
    "        \n",
    "        if is_night_image_classificator(video_output):\n",
    "            vehicle.set_light_state(carla.VehicleLightState(carla.VehicleLightState.HighBeam))\n",
    "        else:\n",
    "            vehicle.set_light_state(carla.VehicleLightState(carla.VehicleLightState.NONE))\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    camera.destroy()\n",
    "    vehicle.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-svs-lab04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
